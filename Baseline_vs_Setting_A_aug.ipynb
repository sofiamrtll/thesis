{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711a7e76-91a0-4b23-ba2c-df7d57910b06",
   "metadata": {},
   "source": [
    "# Baseline vs m6A - setting A with augmentation - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197e38b-bed0-4ec6-87c2-098afc14ce50",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02746f3-4970-4ea5-bd8c-9df9cd70ce63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 04:46:05.494203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-16 04:46:06.170250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/home/ubuntu/')\n",
    "os.chdir('/home/ubuntu/')\n",
    "import src.model\n",
    "importlib.reload(src.model)\n",
    "import src.model as mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afeb407e-c030-4600-84d8-46dc3e0d669c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all paths\n",
    "datapath = '/mnt/data/'\n",
    "resultspath = '/mnt/data/results/'\n",
    "predictionspath = '/mnt/data/results/all_predictions/'\n",
    "plotspath = '/mnt/data/results/plots/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183bad4-6220-4768-ad8d-3d9d2418011d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "Starting preparation of the dataset for RBM15_HepG2\n"
     ]
    }
   ],
   "source": [
    "# Preparation of the dataset for setting A with bound and unbound sequences ( pos and neg1) \n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "path = f'{datapath}processed/ENCODE-Sofia/'\n",
    "directory1 = os.listdir(path)\n",
    "\n",
    "df_methylation = pd.read_csv(f'{resultspath}methylation_rate.csv')\n",
    "df_high = df_methylation[df_methylation.methylation == 'high']\n",
    "list_high_meth = list(df_high.RBP)\n",
    "\n",
    "for folder in directory1:\n",
    "    if folder in list_high_meth:  # to be done for high methylation RBPs\n",
    "    #if folder == 'RBM15_HepG2':\n",
    "        try:\n",
    "            # Encoding input files --> augmentation\n",
    "            path_figure = f'{plotspath}/summary_metrics/{folder}/'\n",
    "            pos, neg1, neg2, pos_t, neg1_t, neg2_t = mdl.prepare_raw_dataset_m6A(\n",
    "                path, folder, True)\n",
    "            #try:\n",
    "            # JUST RBP INFORMATION\n",
    "            output_folder = '_baseline_A_aug'\n",
    "\n",
    "            # preparing the files and labels following the setting A rules --> 4 channels, no downsampling\n",
    "            pos_filt, neg1_filt, pos_t_filt, neg1_t_filt, labels_pos, labels_neg1, labels_pos_t, labels_neg1_t = mdl.settingA(\n",
    "                pos, neg1, pos_t, neg1_t, 4, False)\n",
    "\n",
    "            # finalizing the dataset merging positive and the chosen negative ( either unbound - neg1- or bound to other RBPs -neg2- )\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test = mdl.finalize_dataset(\n",
    "                folder, pos_filt, neg1_filt, pos_t_filt, neg1_t_filt,\n",
    "                labels_pos, labels_neg1, labels_pos_t, labels_neg1_t, path_figure, output_folder)\n",
    "    \n",
    "            # creating the baseline model with the right input shape\n",
    "            #model = keras.models.load_model(f'{resultspath}best_models/best_hps_model{folder}')\n",
    "            model = mdl.create_baseline_standard()\n",
    "            # training the model on the new datasets\n",
    "            y_labels = np.reshape(y_train, (len(y_train), ))\n",
    "            class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                                 classes=np.unique(y_labels),\n",
    "                                                 y=y_labels)\n",
    "            class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "            mdl.training_model(model, class_weights, x_train, y_train, x_val, y_val,\n",
    "                               x_test, y_test, folder, resultspath, output_folder, path_figure)  # trains the model with best hyperparameters \n",
    "\n",
    "            # evaluation and storage of the predicted labels\n",
    "            model_path = (f'{resultspath}best_models/{output_folder}/%s' % folder)\n",
    "            mdl.testing_model(model_path, folder, x_test, y_test,\n",
    "                              predictionspath, output_folder, path_figure)\n",
    "\n",
    "            # M6A DATA INCLUDED\n",
    "            output_folder = '_setting_A_aug'\n",
    "\n",
    "            # preparing the files and labels following the setting A rules --> 5 channels, no downsampling\n",
    "            pos_filt, neg1_filt, pos_t_filt, neg1_t_filt, labels_pos, labels_neg1, labels_pos_t, labels_neg1_t = mdl.settingA(\n",
    "                pos, neg1, pos_t, neg1_t, 5, False)\n",
    "\n",
    "            # finalizing the dataset merging positive and the chosen negative (either unbound - neg1- or bound to other RBPs -neg2-)\n",
    "            x_train, y_train, x_val, y_val, x_test, y_test = mdl.finalize_dataset(\n",
    "                folder, pos_filt, neg1_filt, pos_t_filt, neg1_t_filt,\n",
    "                labels_pos, labels_neg1, labels_pos_t, labels_neg1_t, path_figure, output_folder)\n",
    "\n",
    "            # creating the baseline model with the right input shape\n",
    "            #model = keras.models.load_model(f'{resultspath}best_models/best_hps_model_5{folder}')\n",
    "            model = mdl.create_baseline_model((400, 5))\n",
    "\n",
    "            # training the model on the new datasets\n",
    "            y_labels = np.reshape(y_train, (len(y_train), ))\n",
    "            class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                                 classes=np.unique(y_labels),\n",
    "                                                 y=y_labels)\n",
    "            class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "            mdl.training_model(model, class_weights, x_train, y_train, x_val, y_val,\n",
    "                               x_test, y_test, folder, resultspath, output_folder, path_figure)  # trains the model with best hyperparameters \n",
    "\n",
    "            # evaluation and storage of the predicted labels\n",
    "            model_path = (f'{resultspath}best_models/{output_folder}/%s' % folder)\n",
    "            mdl.testing_model(model_path, folder, x_test, y_test,\n",
    "                              predictionspath, output_folder, path_figure)\n",
    "        except:\n",
    "            print(f'Exception occurred in 5 channel {folder}')\n",
    "            continue\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd7f2ac2-ceb8-4781-8a4e-d07f7695c860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7848"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2368d9-6b7e-48b0-b23a-d15f71f7b421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfba1f4-6a71-40db-a61d-c8c56df31d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1fc09b-e43f-402e-aabb-5d04541b9f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59ab4d-b85f-47e8-a9d6-d99346044af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
