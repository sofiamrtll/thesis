{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719a6a61-7587-464a-bed2-14117362b205",
   "metadata": {},
   "source": [
    "# Baseline vs m6A - setting A - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6e643-0dac-4d6a-ab49-753e4adcab51",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6e51aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 10:49:35.249227: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 10:49:36.025750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%load_ext line_profiler\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import compute_class_weight\n",
    "import pandas as pd\n",
    "from tensorflow import keras \n",
    "\n",
    "sys.path.append('/home/ubuntu/')\n",
    "os.chdir('/home/ubuntu/')\n",
    "import src.model\n",
    "importlib.reload(src.model)\n",
    "import src.model as mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7b5ecc-f5f3-4674-a0cb-663e6188a671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all paths\n",
    "datapath = '/mnt/data/'\n",
    "resultspath = '/mnt/data/results/'\n",
    "predictionspath = '/mnt/data/results/all_predictions/'\n",
    "plotspath = '/mnt/data/results/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c1ddd5-3486-4005-8973-eaf2ae3c750d",
   "metadata": {
    "tags": []
   },
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%load_ext line_profiler\n",
    "\n",
    "path = f'{datapath}processed/ENCODE-Sofia/'\n",
    "directory1 = os.listdir(path)\n",
    "\n",
    "def prepare_raw_dataset_m6A(path, current_folder):\n",
    "    augmentation= False\n",
    "    print('Starting preparation of the dataset for %s' % current_folder)\n",
    "\n",
    "    folder = current_folder #RBP\n",
    "    directory2 = os.listdir(f'{path}{folder}')\n",
    "\n",
    "    seq_list_pos = np.zeros((1, 400, 5))\n",
    "    seq_list_neg1 = np.zeros((1, 400, 5))\n",
    "    seq_list_neg2 = np.zeros((1, 400, 5))\n",
    "    seq_list_pos_test = np.zeros((1, 400, 5))\n",
    "    seq_list_neg1_test = np.zeros((1, 400, 5))\n",
    "    seq_list_neg2_test = np.zeros((1, 400, 5))\n",
    "\n",
    "    for folder2 in directory2:  # fold0, fold1..\n",
    "        #directory3 = os.listdir(f'{path}{folder}/{folder2}')\n",
    "\n",
    "        if folder2 != \"fold-4\":  # to be split into training and validation\n",
    "            seq_list_pos_file, seq_list_neg1_file, seq_list_neg2_file = mdl.getonehotencoded_files(\n",
    "                f'{path}{folder}/{folder2}', augmentation)\n",
    "\n",
    "            seq_list_pos = np.vstack((seq_list_pos, seq_list_pos_file))\n",
    "            seq_list_neg1 = np.vstack((seq_list_neg1, seq_list_neg1_file))\n",
    "            seq_list_neg2 = np.vstack((seq_list_neg2, seq_list_neg2_file))\n",
    "\n",
    "        if folder2 == \"fold-4\":  # for testing\n",
    "            seq_list_pos_test_file, seq_list_neg1_test_file, seq_list_neg2_test_file = mdl.getonehotencoded_files(\n",
    "                f'{path}{folder}/{folder2}', augmentation)\n",
    "\n",
    "            seq_list_pos_test = np.vstack((seq_list_pos_test,\n",
    "                                           seq_list_pos_test_file))\n",
    "            seq_list_neg1_test = np.vstack((seq_list_neg1_test,\n",
    "                                            seq_list_neg1_test_file))\n",
    "            seq_list_neg2_test = np.vstack((seq_list_neg2_test,\n",
    "                                            seq_list_neg2_test_file))\n",
    "\n",
    "    seq_list_pos = np.delete(seq_list_pos, 0, 0)\n",
    "    seq_list_neg1 = np.delete(seq_list_neg1, 0, 0)\n",
    "    seq_list_neg2 = np.delete(seq_list_neg2, 0, 0)\n",
    "\n",
    "    seq_list_pos_test = np.delete(seq_list_pos_test, 0, 0)\n",
    "    seq_list_neg1_test = np.delete(seq_list_neg1_test, 0, 0)\n",
    "    seq_list_neg2_test = np.delete(seq_list_neg2_test, 0, 0)\n",
    "    return \n",
    "\n",
    "\n",
    "%lprun -f prepare_raw_dataset_m6A(path,'RBM15_HepG2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48b448-d835-44d5-a66c-39058d9da36f",
   "metadata": {},
   "source": [
    "# Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a9250-020c-481b-8d70-7e705020e6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "Starting preparation of the dataset for RBM15_HepG2\n"
     ]
    }
   ],
   "source": [
    "# Preparation of the dataset for setting A with bound and unbound sequences ( pos and neg1) \n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "path = f'{datapath}processed/ENCODE-Sofia/'\n",
    "directory1 = os.listdir(path)\n",
    "\n",
    "df_methylation = pd.read_csv(f'{resultspath}methylation_rate.csv')\n",
    "df_high = df_methylation[df_methylation.methylation == 'high']\n",
    "list_high_meth = list(df_high.RBP)\n",
    "\n",
    "for folder in directory1:\n",
    "    #if folder in list_high_meth :#to be done for high methylation RBPs\n",
    "    if folder == 'PCBP1_HepG2':\n",
    "        #try:\n",
    "        # Encoding input files --> no augmentation\n",
    "        path_figure = f'{plotspath}summary_metrics/{folder}/'\n",
    "        pos, neg1, neg2, pos_t, neg1_t, neg2_t = mdl.prepare_raw_dataset_m6A(path, folder, False)\n",
    "\n",
    "        # JUST RBP INFORMATION\n",
    "        output_folder = '_baseline_A'\n",
    "\n",
    "        # preparing the files and labels following the setting A rules --> 4 channels, no downsampling\n",
    "        pos_filt, neg1_filt, pos_t_filt, neg1_t_filt, labels_pos, labels_neg1, labels_pos_t, labels_neg1_t = mdl.settingA(\n",
    "            pos, neg1, pos_t, neg1_t, 4, True)\n",
    "\n",
    "        # finalizing the dataset merging positive and the chosen negative ( either unbound - neg1- or bound to other RBPs -neg2- )\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = mdl.finalize_dataset(\n",
    "            folder, pos_filt, neg1_filt, pos_t_filt, neg1_t_filt,\n",
    "            labels_pos, labels_neg1, labels_pos_t, labels_neg1_t, path_figure, output_folder)\n",
    "\n",
    "        # creating the baseline model with the right input shape\n",
    "        #model = keras.models.load_model(f'{resultspath}best_models/best_hps_model{folder}')\n",
    "        model = mdl.create_baseline_standard()\n",
    "        # training the model on the new datasets\n",
    "        y_labels = np.reshape(y_train, (len(y_train), ))\n",
    "        class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                             classes=np.unique(y_labels),\n",
    "                                             y=y_labels)\n",
    "        class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "        mdl.training_model(model, class_weights, x_train, y_train, x_val, y_val,\n",
    "                           x_test, y_test, folder, resultspath, output_folder, path_figure)  # trains the model with best hyperparameters \n",
    "\n",
    "        # evaluation and storage of the predicted labels\n",
    "        model_path = (f'{resultspath}best_models/{output_folder}/%s' %folder)\n",
    "        mdl.testing_model(model_path, folder, x_test, y_test,\n",
    "                          predictionspath, output_folder, path_figure)\n",
    "\n",
    "        # M6A DATA INCLUDED\n",
    "        output_folder = '_setting_A'\n",
    "\n",
    "        # preparing the files and labels following the setting A rules --> 5 channels, no downsampling\n",
    "        pos_filt, neg1_filt, pos_t_filt, neg1_t_filt, labels_pos, labels_neg1, labels_pos_t, labels_neg1_t = mdl.settingA(\n",
    "            pos, neg1, pos_t, neg1_t, 5, True)\n",
    "\n",
    "        # finalizing the dataset merging positive and the chosen negative (either unbound - neg1- or bound to other RBPs -neg2-)\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = mdl.finalize_dataset(\n",
    "            folder, pos_filt, neg1_filt, pos_t_filt, neg1_t_filt,\n",
    "            labels_pos, labels_neg1, labels_pos_t, labels_neg1_t, path_figure, output_folder)\n",
    "\n",
    "        # creating the baseline model with the right input shape\n",
    "        #model = keras.models.load_model(f'{resultspath}best_models/best_hps_model_5{folder}')\n",
    "        model = mdl.create_baseline_model((400, 5))\n",
    "        # training the model on the new datasets\n",
    "        y_labels = np.reshape(y_train, (len(y_train), ))\n",
    "        class_weights = compute_class_weight(class_weight=\"balanced\",\n",
    "                                             classes=np.unique(y_labels),\n",
    "                                             y=y_labels)\n",
    "        class_weights = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "        mdl.training_model(model, class_weights, x_train, y_train, x_val, y_val,\n",
    "                           x_test, y_test, folder, resultspath, output_folder, path_figure)  # trains the model with best hyperparameters \n",
    "\n",
    "        # evaluation and storage of the predicted labels\n",
    "        model_path = (f'{resultspath}best_models/{output_folder}/%s' % folder)\n",
    "        mdl.testing_model(model_path, folder, x_test, y_test,\n",
    "                          predictionspath, output_folder, path_figure)\n",
    "        #except:  # I don't remember which type of error was raised \n",
    "            #print(f'Exception occurred in {folder}')\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb29391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7bb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
