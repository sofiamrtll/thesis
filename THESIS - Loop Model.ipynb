{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da6bb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import shlex, subprocess\n",
    "import os , sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9ad826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "def fasta_to_onehotencode(seq) : \n",
    "    #values = list(seq)\n",
    "    #values = np.array(values)\n",
    "    base2int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    # label = int(line.strip()[1])\n",
    "    \n",
    "    \n",
    "    sequence = seq \n",
    "    # Encode sequence bases as integers, i.e. A as 0, C as 1, etc.\n",
    "    sequence_int = [base2int.get(base, 9999) for base in sequence]\n",
    "    \n",
    "    sequence_onehot = tf.one_hot(sequence_int, depth=4)\n",
    "    \n",
    "        \n",
    "    return sequence_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a98ed34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastatoarray(fasta_sequences) :\n",
    "    seq_array = np.zeros((1,400,4)) \n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        new_sequence = fasta_to_onehotencode(sequence) #onehotencode(sequence)\n",
    "        new_sequence = np.expand_dims(new_sequence, axis =0)\n",
    "        seq_array = np.vstack((seq_array,new_sequence))\n",
    "    seq_array = np.delete(seq_array, 0, 0) #to remove the first array of zeros \n",
    "    return seq_array  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81b39702",
   "metadata": {},
   "outputs": [],
   "source": [
    "_start_time = time.time()\n",
    "#change a bit this function or cite \n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b86d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path, current_folder) : \n",
    "    print('Starting preparation of the dataset for %s' %current_folder)\n",
    "    \n",
    "    folder = current_folder\n",
    "    directory2 = os.listdir(path+ '/' + folder)\n",
    "    seq_list_positive = np.zeros((1,400,4)) \n",
    "    seq_list_negative = np.zeros((1,400,4)) \n",
    "    seq_list_positive_test = np.zeros((1,400,4)) \n",
    "    seq_list_negative_test = np.zeros((1,400,4)) \n",
    "\n",
    "    for folder2 in directory2 :\n",
    "        directory3 = os.listdir(path+ '/' + folder + '/' + folder2)\n",
    "\n",
    "        if folder2 != \"fold-4\": #to be split into training and validation\n",
    "\n",
    "            seq_list_positive_file = np.zeros((1,400,4)) \n",
    "            seq_list_negative_file = np.zeros((1,400,4)) \n",
    "\n",
    "            for file in directory3 :\n",
    "\n",
    "                if \"fasta\" in file :\n",
    "                    fasta_sequences = SeqIO.parse(open(path+ '/' + folder + '/' + folder2+ '/' + file),'fasta')\n",
    "                    seq_array = fastatoarray(fasta_sequences)\n",
    "\n",
    "                    if \"positive\" in file : \n",
    "                        seq_list_positive_file = np.vstack((seq_list_positive_file, seq_array))\n",
    "\n",
    "\n",
    "                    if \"negative-1\" in file: # 2 neg: 1 pos with 'negative' --> 1 neg : 1 pos 'negative-1'\n",
    "                        seq_list_negative_file = np.vstack((seq_list_negative_file, seq_array))\n",
    "\n",
    "            seq_list_negative_file = np.delete(seq_list_negative_file, 0, 0)\n",
    "            seq_list_positive_file = np.delete(seq_list_positive_file, 0, 0)\n",
    "\n",
    "            seq_list_positive = np.vstack((seq_list_positive, seq_list_positive_file))\n",
    "            seq_list_negative = np.vstack((seq_list_negative, seq_list_negative_file))\n",
    "\n",
    "\n",
    "\n",
    "        if folder2 == \"fold-4\": #for testing\n",
    "\n",
    "                seq_list_positive_test_file = np.zeros((1,400,4)) \n",
    "                seq_list_negative_test_file = np.zeros((1,400,4)) \n",
    "\n",
    "                for file in directory3 :\n",
    "\n",
    "                    if \"fasta\" in file :\n",
    "                        fasta_sequences = SeqIO.parse(open(path+ '/' + folder + '/' + folder2+ '/' + file),'fasta')\n",
    "                        seq_array = fastatoarray(fasta_sequences)\n",
    "\n",
    "                        if \"positive\" in file : \n",
    "                            seq_list_positive_test_file = np.vstack((seq_list_positive_test_file, seq_array))\n",
    "\n",
    "\n",
    "                        if \"negative-1\" in file: \n",
    "                            seq_list_negative_test_file = np.vstack((seq_list_negative_test_file, seq_array))\n",
    "\n",
    "                seq_list_negative_test_file = np.delete(seq_list_negative_test_file, 0, 0)\n",
    "                seq_list_positive_test_file = np.delete(seq_list_positive_test_file, 0, 0)\n",
    "\n",
    "                seq_list_positive_test = np.vstack((seq_list_positive_test, seq_list_positive_test_file))\n",
    "                seq_list_negative_test = np.vstack((seq_list_negative_test, seq_list_negative_test_file))\n",
    "\n",
    "                seq_list_negative_test = np.delete(seq_list_negative_test, 0, 0)\n",
    "                seq_list_positive_test = np.delete(seq_list_positive_test, 0, 0)  \n",
    "\n",
    "\n",
    "\n",
    "    seq_list_negative = np.delete(seq_list_negative, 0, 0)\n",
    "    seq_list_positive = np.delete(seq_list_positive, 0, 0)\n",
    "    \n",
    "    \n",
    "    #prep labels\n",
    "    labels_positive = np.ones((np.shape(seq_list_positive)[0], 1))\n",
    "\n",
    "    labels_negative = np.zeros((np.shape(seq_list_negative)[0], 1))\n",
    "\n",
    "    labels_positive_test = np.ones((np.shape(seq_list_positive_test)[0], 1))\n",
    "\n",
    "    labels_negative_test = np.zeros((np.shape(seq_list_negative_test)[0], 1))\n",
    "    print('Shape of labels: \\n-positive : ',np.shape(labels_negative),'\\n-negative : ', np.shape(labels_negative),'\\n-positive validation : ',np.shape(labels_positive_test),'\\n-negative validation : ',np.shape(labels_negative_test))\n",
    "    \n",
    "    \n",
    "    #merging datasets\n",
    "    x = np.vstack((seq_list_positive, seq_list_negative))\n",
    "\n",
    "    x_test = np.vstack((seq_list_positive_test, seq_list_negative_test))\n",
    "\n",
    "    y = np.vstack((labels_positive, labels_negative))\n",
    "\n",
    "    y_test = np.vstack((labels_positive_test, labels_negative_test))\n",
    "    \n",
    "    #creating the validation set\n",
    "\n",
    "    #parameters \n",
    "    test_size = 0.2\n",
    "\n",
    "    #test set\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=test_size, shuffle= True)\n",
    "    x_test, y_test = shuffle(x_test, y_test, random_state=0)\n",
    "\n",
    "    y_train = y_train.astype(\"float32\")#actually useful?\n",
    "    y_val =y_val.astype(\"float32\")\n",
    "    y_test = y_test.astype(\"float32\")\n",
    "\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_val = x_val.astype(\"float32\")\n",
    "    x_test =x_test.astype(\"float32\")\n",
    "\n",
    "\n",
    "\n",
    "    print('Shape of datasets: \\n-training set : ',np.shape(x_train),'\\n-validation set : ',np.shape(x_val),'\\n-testing set : ', np.shape(x_test))\n",
    "    \n",
    "    #checking class ditribution in the whole dataset and training set\n",
    "\n",
    "    print('Label frequencies among the dataset %s' %current_folder)\n",
    "    plt.hist(y)\n",
    "    plt.xticks(range(2))\n",
    "    plt.title('Label Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(y_train)\n",
    "    plt.xticks(range(2))\n",
    "    plt.title('Label Frequency training set')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(y_val)\n",
    "    plt.xticks(range(2))\n",
    "    plt.title('Label Frequency validation set')\n",
    "    plt.show()\n",
    "    return x_train ,y_train ,x_val ,y_val ,x_test ,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32c5b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning of the model architecture \n",
    "def build_model(hp):\n",
    "    \n",
    "    \n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(curve= 'ROC',name='auroc'),\n",
    "      keras.metrics.AUC(curve = 'PR', name='auprc')  \n",
    "    ]\n",
    "\n",
    "   \n",
    "    #the first layer should be a convolutional layer\n",
    "    #conv-maxpooling-dropout-conv-maxpooling-dropout-flatten-(dense-dropout)-dense --> this is the pysster architecture \n",
    "    #how long should the kernel be? \n",
    "    #the parameters are now the default ones from pysster\n",
    "    \n",
    "    input_shape = (400, 4)\n",
    "    \n",
    "    \n",
    "    #hyperparameter search \n",
    "    \n",
    "    hp_filters = hp.Int('filters', min_value = 10, max_value = 60, step = 10)\n",
    "    hp_kernel_size = hp.Int('kernel_size', min_value = 10, max_value = 60, step = 5)\n",
    "    hp_pool_size = hp.Int('pool_size', min_value = 1, max_value = 10, step = 1)\n",
    "    hp_strides = hp.Int('strides', min_value = 1, max_value = 10, step = 1)\n",
    "    hp_learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    hp_padding = hp.Choice('padding', ['valid','same'])\n",
    "    hp_kernel_initializer = hp.Choice('initiaizer', ['random_normal','random_uniform', 'he_normal', 'glorot_normal'])\n",
    "    hp_activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create model\n",
    "    \n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.InputLayer(input_shape= input_shape))\n",
    "    #model.add(keras.layers.Dropout(0.3)) -- seems better without this step\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(filters=hp_filters,kernel_size=hp_kernel_size,\n",
    "              kernel_initializer=hp_kernel_initializer, \n",
    "              activation=hp_activation,input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=hp_pool_size, strides=hp_strides, padding=hp_padding))#valid or same?  \n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Conv1D(filters=hp_filters,kernel_size=hp_kernel_size,\n",
    "              kernel_initializer= hp_kernel_initializer, \n",
    "              activation=hp_activation ,input_shape=input_shape ))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=hp_pool_size, strides=hp_strides, padding=hp_padding))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Flatten())#without parameters\n",
    "    \n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units separately.\n",
    "            units=hp.Int(f\"units_{i}\", min_value=32, max_value=1024, step=32),\n",
    "            activation = hp_activation\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=hp_activation))\n",
    "\n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))#what should be the output shape? 1? \n",
    "\n",
    "    \n",
    "    #many models train better when reducing the learning rate gradually -- not in this case!! see model2\n",
    "    #lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                                                                 # 0.001,\n",
    "                                                                 # decay_steps=50*1000,\n",
    "                                                                 # decay_rate=1,\n",
    "                                                                  #staircase=False)\n",
    "    \n",
    "    \n",
    "    # Compile model\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(hp_learning_rate), metrics=METRICS)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eaf308e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_model(x_train ,y_train ,x_val ,y_val ,x_test ,y_test, folder) : \n",
    "    \n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(curve= 'ROC',name='auroc'),\n",
    "      keras.metrics.AUC(curve = 'PR', name='auprc')  \n",
    "    ]\n",
    "    \n",
    "    my_callbacks1 = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=2), #better to reduce to 2 for the search \n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "        ]\n",
    "    \n",
    "        my_callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=2), #better to reduce to 2 for the search \n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "        ]\n",
    "\n",
    "\n",
    "    model2 = build_model(keras_tuner.HyperParameters())\n",
    "\n",
    "    print(model2.summary())\n",
    "\n",
    "    \n",
    "    tuner = keras_tuner.RandomSearch(\n",
    "        hypermodel=build_model,\n",
    "        #objective=keras_tuner.Objective(\"val_auroc\", direction=\"max\"), #val_loss , val_accuracy .... 77\n",
    "        objective = keras_tuner.Objective(\"val_loss\", direction=\"min\"),\n",
    "        max_trials=150,\n",
    "        executions_per_trial=1, #probably better to change to 1 and increase the max_trials\n",
    "        overwrite=True,\n",
    "        directory=\"my_dir\",\n",
    "        project_name=\"models\",\n",
    "    )\n",
    "\n",
    "    print(tuner.search_space_summary())\n",
    "\n",
    "\n",
    "    tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val), callbacks = my_callbacks1)\n",
    "    \n",
    "    # Get the top 2 models.\n",
    "    models2 = tuner.get_best_models(num_models=4)\n",
    "    best_model2 = models2[0]\n",
    "    # Build the model.\n",
    "    # Needed for `Sequential` without specified `input_shape`.\n",
    "    best_model2.build(input_shape=(None, 400, 4))\n",
    "    best_model2.summary()\n",
    "\n",
    "    \n",
    "    best_hps = tuner.get_best_hyperparameters(5)\n",
    "    # Build the model with the best hp.\n",
    "    model2 = build_model(best_hps[0])\n",
    "    # Fit with the entire dataset.\n",
    "\n",
    "    history = model2.fit(x_train, y_train, epochs=200, validation_data= (x_val,y_val), callbacks = my_callbacks)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # list all data in history --> add name of the rbp!!!!\n",
    "\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    plt.title('Best model evaluation for %s' %folder)\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for auroc \n",
    "    plt.plot(history.history['auroc'])\n",
    "    plt.plot(history.history['val_auroc'])\n",
    "    plt.plot(history.history['auprc'])\n",
    "    plt.plot(history.history['val_auprc'])\n",
    "    plt.title('model auroc and auprc')\n",
    "    plt.ylabel('auroc and auprc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['auroc_train', 'auroc_test','auprc_train', 'auprc_test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    model2.save('best_models/best_model4_%s' %folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d3a81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(path , current_folder, x_test, y_test) : \n",
    "    reconstructed_model = keras.models.load_model(path)\n",
    "    \n",
    "    y_pred = reconstructed_model.predict(x_test)\n",
    "\n",
    "    threshold = 0.5\n",
    "\n",
    "    y_pred2 = np.where(y_pred > threshold, 1,0)\n",
    "    \n",
    "    #Get the confusion matrix model1\n",
    "\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred2)\n",
    "\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                    cf_matrix.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "              zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    \n",
    "    #saving the true and predicted labels\n",
    "    \n",
    "    df= pd.DataFrame(y_pred, columns = ['Predictions'])\n",
    "    df['True'] = y_test\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(df['True'], df['Predictions'], drop_intermediate=False)\n",
    "    \n",
    "    roc_auc = metrics.roc_auc_score(df['True'], df['Predictions'])\n",
    "    \n",
    "\n",
    "    # Generate figure\n",
    "    fig = pl.figure(figsize=(14,7))\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    pl.plot(fpr, tpr, label=\" (AUC=%.2f)\" % roc_auc)\n",
    "    ax.plot([0,1], [0,1], color=\"grey\",label=\"Random Classifier\",linestyle=\"--\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.grid(color=\"#CCCCCC\")\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    #rbp = str(file).split('.')[0]\n",
    "    pt.title('AUROC %s' % current_folder)\n",
    "    pl.legend()\n",
    "    pl.tight_layout()\n",
    "    \n",
    "\n",
    "    #saving the predictions (0,1) in a csv file -- in probabilities \n",
    "\n",
    "    df.to_csv(\"predictions/%s_4.csv\" % current_folder)\n",
    "    \n",
    "    print(\"Prediction saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9c2826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 128 Complete [00h 00m 00s]\n",
      "\n",
      "Best val_loss So Far: 0.46264326572418213\n",
      "Total elapsed time: 00h 20m 18s\n",
      "\n",
      "Search: Running Trial #129\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "10                |50                |filters\n",
      "40                |55                |kernel_size\n",
      "5                 |9                 |pool_size\n",
      "10                |4                 |strides\n",
      "0.002051          |0.00031558        |lr\n",
      "valid             |valid             |padding\n",
      "random_uniform    |random_uniform    |initiaizer\n",
      "relu              |tanh              |activation\n",
      "2                 |2                 |num_layers\n",
      "736               |288               |units_0\n",
      "True              |False             |dropout\n",
      "32                |64                |units_1\n",
      "352               |352               |units_2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 250, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 215, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 286, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 212, in _build_and_fit_model\n",
      "    model = self._try_build(hp)\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 154, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 145, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"/tmp/ipykernel_260924/303801283.py\", line 53, in build_model\n",
      "    model.add(keras.layers.Conv1D(filters=hp_filters,kernel_size=hp_kernel_size,\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/tensorflow/python/trackable/base.py\", line 205, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 347, in compute_output_shape\n",
      "    raise ValueError(\n",
      "ValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_1. Consider increasing the input size. Received input shape [None, 36, 10] which would produce output shape with a zero or negative value in a dimension.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 250, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 215, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 286, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 212, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 154, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 145, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"/tmp/ipykernel_260924/303801283.py\", line 53, in build_model\n    model.add(keras.layers.Conv1D(filters=hp_filters,kernel_size=hp_kernel_size,\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/tensorflow/python/trackable/base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 347, in compute_output_shape\n    raise ValueError(\nValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_1. Consider increasing the input size. Received input shape [None, 36, 10] which would produce output shape with a zero or negative value in a dimension.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m x_train ,y_train ,x_val ,y_val ,x_test ,y_test \u001b[38;5;241m=\u001b[39m prepare_dataset(path, folder)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#prepare and save the best model in the respective folder \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mprepare_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#evaluation and storage of the predicted labels\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model_path \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_models/best_model4_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m folder)\n",
      "Cell \u001b[0;32mIn[52], line 41\u001b[0m, in \u001b[0;36mprepare_best_model\u001b[0;34m(x_train, y_train, x_val, y_val, x_test, y_test, folder)\u001b[0m\n\u001b[1;32m     27\u001b[0m tuner \u001b[38;5;241m=\u001b[39m keras_tuner\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[1;32m     28\u001b[0m     hypermodel\u001b[38;5;241m=\u001b[39mbuild_model,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m#objective=keras_tuner.Objective(\"val_auroc\", direction=\"max\"), #val_loss , val_accuracy .... 77\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(tuner\u001b[38;5;241m.\u001b[39msearch_space_summary())\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Get the top 2 models.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m models2 \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:211\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:321\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mreport_trial_state(trial\u001b[38;5;241m.\u001b[39mtrial_id, trial\u001b[38;5;241m.\u001b[39mget_state())\n\u001b[0;32m--> 321\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# Display needs the updated trial scored by the Oracle.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display\u001b[38;5;241m.\u001b[39mon_trial_end(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id))\n",
      "File \u001b[0;32m~/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/oracle.py:105\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    104\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[0;32m--> 105\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[1;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/oracle.py:429\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/oracle.py:382\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures excceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m trial\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    385\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 250, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 215, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 286, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 212, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 154, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 145, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"/tmp/ipykernel_260924/303801283.py\", line 53, in build_model\n    model.add(keras.layers.Conv1D(filters=hp_filters,kernel_size=hp_kernel_size,\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/tensorflow/python/trackable/base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 347, in compute_output_shape\n    raise ValueError(\nValueError: One of the dimensions in the output is <= 0 due to downsampling in conv1d_1. Consider increasing the input size. Received input shape [None, 36, 10] which would produce output shape with a zero or negative value in a dimension.\n"
     ]
    }
   ],
   "source": [
    "#change to function the majority of the notebook !! \n",
    "\n",
    "path = '/lustre/groups/crna01/workspace/sofia/gencode/processed/ENCODE-Sofia/'\n",
    "directory1 = os.listdir(path)\n",
    "\n",
    "\n",
    "tic()\n",
    "\n",
    "for folder in directory1:\n",
    "    if folder == 'AARS_K562':\n",
    "    \n",
    "        #preparation of the dataset from the respective folder \n",
    "        x_train ,y_train ,x_val ,y_val ,x_test ,y_test = prepare_dataset(path, folder)\n",
    "\n",
    "        #prepare and save the best model in the respective folder \n",
    "        prepare_best_model(x_train ,y_train ,x_val ,y_val ,x_test ,y_test, folder) \n",
    "\n",
    "        #evaluation and storage of the predicted labels\n",
    "        model_path = ('best_models/best_model4_%s' % folder)\n",
    "        testing_model(model_path , folder, x_test, y_test)\n",
    "tac()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b619f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = ('best_models/best_model2_%s' % folder)\n",
    "testing_model(model_path , folder, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a295dcbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df88d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8a262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c78482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90da441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe64abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3776ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-thesis-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
