{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637bc311",
   "metadata": {},
   "source": [
    "# THESIS - Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a92bfc",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05792d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 15:21:17.161901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import shlex, subprocess\n",
    "import os , sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006f771",
   "metadata": {},
   "source": [
    "# 1. Preparation of the dataset \n",
    "- One hot encoding the sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a078fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should work now \n",
    "def fasta_to_onehotencode(seq) : \n",
    "    #values = list(seq)\n",
    "    #values = np.array(values)\n",
    "    base2int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    # label = int(line.strip()[1])\n",
    "    \n",
    "    \n",
    "    sequence = seq #f.readline().strip()\n",
    "    # Encode sequence bases as integers, i.e. A as 0, C as 1, etc.\n",
    "    sequence_int = [base2int.get(base, 9999) for base in sequence]\n",
    "    \n",
    "    sequence_onehot = tf.one_hot(sequence_int, depth=4)\n",
    "    \n",
    "        \n",
    "    return sequence_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4360b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastatoarray(fasta_sequences) :\n",
    "    seq_array = np.zeros((1,400,4)) \n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        new_sequence = fasta_to_onehotencode(sequence) #onehotencode(sequence)\n",
    "        new_sequence = np.expand_dims(new_sequence, axis =0)\n",
    "        seq_array = np.vstack((seq_array,new_sequence))\n",
    "    seq_array = np.delete(seq_array, 0, 0) #to remove the first array of zeros \n",
    "    return seq_array                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f658b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_start_time = time.time()\n",
    "#change a bit this function or cite \n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1d9b3e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed: 0hour:0min:12sec\n"
     ]
    }
   ],
   "source": [
    "#dataset upload, keeping the first four folders for training and testing and the last one for validation --> try with matrices not list\n",
    "\n",
    "#/lustre/groups/crna01/workspace/sofia/gencode/processed/ENCODE-Sofia/AARS_K562/fold-0/\n",
    "from Bio import SeqIO\n",
    "path = '/lustre/groups/crna01/workspace/sofia/gencode/processed/ENCODE-Sofia/'\n",
    "directory1 = os.listdir(path)\n",
    "\n",
    "\n",
    "tic()\n",
    "\n",
    "for folder in directory1:\n",
    "\n",
    "    if folder == 'AARS_K562': #to be removed later \n",
    "        current_folder = folder\n",
    "        directory2 = os.listdir(path + '/' + folder)\n",
    "        \n",
    "        seq_list_positive = np.zeros((1,400,4)) \n",
    "        seq_list_negative = np.zeros((1,400,4)) \n",
    "        seq_list_positive_test = np.zeros((1,400,4)) \n",
    "        seq_list_negative_test = np.zeros((1,400,4)) \n",
    "        \n",
    "        for folder2 in directory2 :\n",
    "            directory3 = os.listdir(path+ '/' + folder + '/' + folder2)\n",
    "            \n",
    "            if folder2 != \"fold-4\": #to be split into training and validation\n",
    "            \n",
    "                seq_list_positive_file = np.zeros((1,400,4)) \n",
    "                seq_list_negative_file = np.zeros((1,400,4)) \n",
    "\n",
    "                for file in directory3 :\n",
    "\n",
    "                    if \"fasta\" in file :\n",
    "                        fasta_sequences = SeqIO.parse(open(path+ '/' + folder + '/' + folder2+ '/' + file),'fasta')\n",
    "                        seq_array = fastatoarray(fasta_sequences)\n",
    "                        \n",
    "                        if \"positive\" in file : \n",
    "                            seq_list_positive_file = np.vstack((seq_list_positive_file, seq_array))\n",
    "\n",
    "\n",
    "                        if \"negative-1\" in file: # 2 neg: 1 pos with 'negative' --> 1 neg : 1 pos 'negative-1'\n",
    "                            seq_list_negative_file = np.vstack((seq_list_negative_file, seq_array))\n",
    "                            \n",
    "                seq_list_negative_file = np.delete(seq_list_negative_file, 0, 0)\n",
    "                seq_list_positive_file = np.delete(seq_list_positive_file, 0, 0)\n",
    "\n",
    "                seq_list_positive = np.vstack((seq_list_positive, seq_list_positive_file))\n",
    "                seq_list_negative = np.vstack((seq_list_negative, seq_list_negative_file))\n",
    "\n",
    "  \n",
    "                \n",
    "            if folder2 == \"fold-4\": #for testing\n",
    "                     \n",
    "                    seq_list_positive_test_file = np.zeros((1,400,4)) \n",
    "                    seq_list_negative_test_file = np.zeros((1,400,4)) \n",
    "\n",
    "                    for file in directory3 :\n",
    "\n",
    "                        if \"fasta\" in file :\n",
    "                            fasta_sequences = SeqIO.parse(open(path+ '/' + folder + '/' + folder2+ '/' + file),'fasta')\n",
    "                            seq_array = fastatoarray(fasta_sequences)\n",
    "\n",
    "                            if \"positive\" in file : \n",
    "                                seq_list_positive_test_file = np.vstack((seq_list_positive_test_file, seq_array))\n",
    " \n",
    "\n",
    "                            if \"negative-1\" in file: \n",
    "                                seq_list_negative_test_file = np.vstack((seq_list_negative_test_file, seq_array))\n",
    " \n",
    "                    seq_list_negative_test_file = np.delete(seq_list_negative_test_file, 0, 0)\n",
    "                    seq_list_positive_test_file = np.delete(seq_list_positive_test_file, 0, 0)\n",
    "\n",
    "                    seq_list_positive_test = np.vstack((seq_list_positive_test, seq_list_positive_test_file))\n",
    "                    seq_list_negative_test = np.vstack((seq_list_negative_test, seq_list_negative_test_file))\n",
    "    \n",
    "                    seq_list_negative_test = np.delete(seq_list_negative_test, 0, 0)\n",
    "                    seq_list_positive_test = np.delete(seq_list_positive_test, 0, 0)  \n",
    "\n",
    "        \n",
    "                  \n",
    "        seq_list_negative = np.delete(seq_list_negative, 0, 0)\n",
    "        seq_list_positive = np.delete(seq_list_positive, 0, 0)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            \n",
    "tac()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ae695",
   "metadata": {},
   "source": [
    "- Preparation of the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44aa0c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels: \n",
      "-positive :  (2667, 1) \n",
      "-negative :  (2667, 1) \n",
      "-positive validation :  (720, 1) \n",
      "-negative validation :  (720, 1)\n"
     ]
    }
   ],
   "source": [
    "#preparation of the labels for the positive and negative dataset and validation set\n",
    "\n",
    "labels_positive = np.ones((np.shape(seq_list_positive)[0], 1))\n",
    "\n",
    "labels_negative = np.zeros((np.shape(seq_list_negative)[0], 1))\n",
    " \n",
    "labels_positive_test = np.ones((np.shape(seq_list_positive_test)[0], 1))\n",
    "\n",
    "labels_negative_test = np.zeros((np.shape(seq_list_negative_test)[0], 1))\n",
    "print('Shape of labels: \\n-positive : ',np.shape(labels_negative),'\\n-negative : ', np.shape(labels_negative),'\\n-positive validation : ',np.shape(labels_positive_test),'\\n-negative validation : ',np.shape(labels_negative_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894c8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the positive and negative datasets \n",
    "x = np.vstack((seq_list_positive, seq_list_negative))\n",
    "\n",
    "x_test = np.vstack((seq_list_positive_test, seq_list_negative_test))\n",
    "\n",
    "y = np.vstack((labels_positive, labels_negative))\n",
    "\n",
    "y_test = np.vstack((labels_positive_test, labels_negative_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91508dd8",
   "metadata": {},
   "source": [
    "- Splitting of the dataset : test, train and validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fac183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of datasets: \n",
      "-training set :  (4267, 400, 4) \n",
      "-validation set :  (1067, 400, 4) \n",
      "-testing set :  (1440, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "#creation of the validation set \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#parameters \n",
    "test_size = 0.2\n",
    "\n",
    "#test set\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=test_size, shuffle= True)\n",
    "\n",
    "y_train = y_train.astype(\"float32\")#actually useful?\n",
    "y_val =y_val.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_val = x_val.astype(\"float32\")\n",
    "x_test =x_test.astype(\"float32\")\n",
    "\n",
    "\n",
    "\n",
    "print('Shape of datasets: \\n-training set : ',np.shape(x_train),'\\n-validation set : ',np.shape(x_val),'\\n-testing set : ', np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training dataset. --> I HAVE AVOIDED THIS STEP OTHERWISE THE MODEL DOES NOT RUN \n",
    "#parameters\n",
    "batch_size = 32 #--> how much should be my batch size? \n",
    "buffer_size = len(x_train) + 100 #For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n",
    "buffer_size_test= len(x_test) + 100\n",
    "\n",
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=buffer_size).batch(batch_size) \n",
    "\n",
    "# Prepare the testing dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = train_dataset.shuffle(buffer_size=buffer_size_test).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d4aee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking class ditribution in the whole dataset and training set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y)\n",
    "plt.xticks(range(2))\n",
    "plt.title('Label Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.xticks(range(2))\n",
    "plt.title('Label Frequency training set')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(y_val)\n",
    "plt.xticks(range(2))\n",
    "plt.title('Label Frequency validation set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89762bc1",
   "metadata": {},
   "source": [
    "# 2. Model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc4e6e",
   "metadata": {},
   "source": [
    "# 2.1 .compile() \n",
    "- Create the baseline model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a92b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first is .compile() --> to create the baseline model : no dataset\n",
    "def create_baseline():\n",
    "    from tensorflow.keras.optimizers.legacy import Adam\n",
    "   \n",
    "    #the first layer should be a convolutional layer\n",
    "    #conv-maxpooling-dropout-conv-maxpooling-dropout-flatten-(dense-dropout)-dense --> this is the pysster architecture \n",
    "    #how long should the kernel be? \n",
    "    #the parameters are now the default ones from pysster\n",
    "    \n",
    "    #parameters \n",
    "    input_shape = (400, 4)\n",
    "    #batch_size = 32 # --> when batching the dataset, the model gives a graph error \n",
    "    filters = 30\n",
    "    kernel_size = 25\n",
    "    pool_size = 2\n",
    "    strides = 2\n",
    "    #activation ? \n",
    "    #kernel_initializer ? \n",
    "    loss='binary_crossentropy'\n",
    "    optimizer='adam' \n",
    "    metrics=['accuracy']\n",
    "    \n",
    "    # create model\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.InputLayer(input_shape= input_shape))#, batch_size=batch_size))\n",
    "    #model.add(keras.layers.Dropout(0.3)) -- seems better without this step\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(filters=filters,kernel_size=kernel_size,#kernel_size is kernel length right? \n",
    "              kernel_initializer='random_normal', #to be changed once I have the actual input data -- from constant 1 ato random normal\n",
    "             #glorot_uniform(seed=12)\n",
    "              activation='relu'))#,input_shape=input_shape[1:])) #--> idk what to add\n",
    "             #or without data? )\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=pool_size, strides=strides, padding='valid'))#valid or same? padding or not \n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Conv1D(filters=filters,kernel_size=kernel_size,\n",
    "              kernel_initializer= 'random_normal', \n",
    "             #glorot_uniform(seed=12)\n",
    "              activation='relu',input_shape=input_shape ))#--> idk what to add\n",
    "\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=pool_size, strides=strides, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Flatten())#without parameters\n",
    "\n",
    "    model.add(keras.layers.Dense(1024, activation='relu'))#is it always relu? also sigmoid is an option \n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "    \n",
    "    model.add(keras.layers.Dense(128, activation='relu'))#is it always relu? also sigmoid is an option \n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))#what should be the output shape? 1? \n",
    "\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) # for binary classification\n",
    "    \n",
    "    #model.compile( optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-4),# Optimizer\n",
    "                    # Loss function to minimize\n",
    "                    #loss=keras.losses.BinaryCrossentropy(),\n",
    "                    # List of metrics to monitor\n",
    "                    #metrics=[keras.metrics.BinaryAccuracy()],)\n",
    "        #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # for multi class\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600122d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214bf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ed43e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuning of the model architecture \n",
    "def build_model(hp):\n",
    "    \n",
    "    \n",
    "    from tensorflow.keras.optimizers.legacy import Adam\n",
    "   \n",
    "    #the first layer should be a convolutional layer\n",
    "    #conv-maxpooling-dropout-conv-maxpooling-dropout-flatten-(dense-dropout)-dense --> this is the pysster architecture \n",
    "    #how long should the kernel be? \n",
    "    #the parameters are now the default ones from pysster\n",
    "    \n",
    "    #parameters \n",
    "    input_shape = (400, 4)\n",
    "    #batch_size = 32 # --> when batching the dataset, the model gives a graph error \n",
    "    filters = 30\n",
    "    kernel_size = 25\n",
    "    pool_size = 2\n",
    "    strides = 2\n",
    "    #activation ? \n",
    "    #kernel_initializer ? \n",
    "    loss='binary_crossentropy'\n",
    "    optimizer='adam' \n",
    "    metrics=['accuracy']\n",
    "    \n",
    "    # create model\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.InputLayer(input_shape= input_shape))#, batch_size=batch_size))\n",
    "    #model.add(keras.layers.Dropout(0.3)) -- seems better without this step\n",
    "    \n",
    "    model.add(keras.layers.Conv1D(filters=filters,kernel_size=kernel_size,#kernel_size is kernel length right? \n",
    "              kernel_initializer='random_normal', #to be changed once I have the actual input data -- from constant 1 ato random normal\n",
    "             #glorot_uniform(seed=12)\n",
    "              activation='relu'))#,input_shape=input_shape[1:])) #--> idk what to add\n",
    "             #or without data? )\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=pool_size, strides=strides, padding='valid'))#valid or same? padding or not \n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Conv1D(filters=filters,kernel_size=kernel_size,\n",
    "              kernel_initializer= 'random_normal', \n",
    "             #glorot_uniform(seed=12)\n",
    "              activation='relu',input_shape=input_shape ))#--> idk what to add\n",
    "\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=pool_size, strides=strides, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(keras.layers.Flatten())#without parameters\n",
    "    \n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units separately.\n",
    "            units=hp.Int(f\"units_{i}\", min_value=32, max_value=1024, step=32),\n",
    "            activation = 'relu'\n",
    "            #activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"relu\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    \n",
    "    \n",
    "\n",
    "    #model.add(keras.layers.Dense(1024, activation='relu'))#is it always relu? also sigmoid is an option\n",
    "    '''model.add(\n",
    "        layers.Dense(\n",
    "            # Define the hyperparameter.\n",
    "            units=hp.Int(\"units\", min_value=128, max_value=2400, step=32),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "    \n",
    "    #model.add(keras.layers.Dense(128, activation='relu'))#is it always relu? also sigmoid is an option \n",
    "    model.add(\n",
    "        layers.Dense(\n",
    "            # Define the hyperparameter.\n",
    "            units=hp.Int(\"units\", min_value=32, max_value=128, step=32),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )'''\n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))#what should be the output shape? 1? \n",
    "\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy']) # for binary classification\n",
    "    \n",
    "    #model.compile( optimizer=keras.optimizers.legacy.Adam(learning_rate=1e-4),# Optimizer\n",
    "                    # Loss function to minimize\n",
    "                    #loss=keras.losses.BinaryCrossentropy(),\n",
    "                    # List of metrics to monitor\n",
    "                    #metrics=[keras.metrics.BinaryAccuracy()],)\n",
    "        #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # for multi class\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e0c86323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 376, 30)           3030      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 188, 30)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 188, 30)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 164, 30)           22530     \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 82, 30)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 82, 30)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2460)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                78752     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,653\n",
      "Trainable params: 104,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "\n",
    "model1 = build_model(keras_tuner.HyperParameters())\n",
    "\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "987e93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"accuracy\", #val_loss , val_accuracy .... \n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8cd16ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 1024, 'step': 32, 'sampling': 'linear'}\n",
      "dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "lr (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bb94e267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 26s]\n",
      "accuracy: 0.6414342522621155\n",
      "\n",
      "Best accuracy So Far: 0.7426763574282328\n",
      "Total elapsed time: 00h 02m 16s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ff8a893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 376, 30)           3030      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 188, 30)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 188, 30)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 164, 30)           22530     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 82, 30)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 82, 30)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2460)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 896)               2205056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                28704     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,717\n",
      "Trainable params: 2,260,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=4)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 400, 4))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c5a10ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir/helloworld\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fdfadf977f0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 896\n",
      "dropout: True\n",
      "lr: 0.0004893954054196937\n",
      "units_1: 32\n",
      "units_2: 32\n",
      "Score: 0.7426763574282328\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 192\n",
      "dropout: True\n",
      "lr: 0.0016380235981496075\n",
      "units_1: 800\n",
      "units_2: 192\n",
      "Score: 0.7310366233189901\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 960\n",
      "dropout: False\n",
      "lr: 0.00035910093218825\n",
      "units_1: 32\n",
      "units_2: 64\n",
      "Score: 0.6654948790868124\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 384\n",
      "dropout: False\n",
      "lr: 0.00024335509762462415\n",
      "units_1: 224\n",
      "units_2: 160\n",
      "Score: 0.6505741675694784\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 448\n",
      "dropout: False\n",
      "lr: 0.000501777635589437\n",
      "units_1: 96\n",
      "units_2: 928\n",
      "Score: 0.6414342522621155\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4c905718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 [==============================] - 3s 13ms/step - loss: 0.6472 - accuracy: 0.6067\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.5869 - accuracy: 0.6775\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.5748 - accuracy: 0.6910\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.5512 - accuracy: 0.7372\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.5430 - accuracy: 0.7492\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.5328 - accuracy: 0.7572\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.5100 - accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 0.4907 - accuracy: 0.7898\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.4778 - accuracy: 0.7992\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 0.4595 - accuracy: 0.8065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdfad8152a0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model1 = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((x_train, x_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "model1.fit(x=x_all, y=y_all, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c0355c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/best_model_AARS_K562/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/best_model_AARS_K562/assets\n"
     ]
    }
   ],
   "source": [
    "model1.save('best_models/best_model_%s' % current_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "17591bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_models/best_model_AARS_K562\n"
     ]
    }
   ],
   "source": [
    "print('best_models/best_model_%s' % current_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd68e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3cddd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.layers.convolutional.conv1d.Conv1D object at 0x7fdfd06b3be0>, <keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7fdfd06b3b80>, <keras.layers.regularization.dropout.Dropout object at 0x7fdfd06b1cc0>, <keras.layers.convolutional.conv1d.Conv1D object at 0x7fdfd06b3190>, <keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7fdfd07041c0>, <keras.layers.regularization.dropout.Dropout object at 0x7fe06695d150>, <keras.layers.reshaping.flatten.Flatten object at 0x7fe0141091e0>, <keras.layers.core.dense.Dense object at 0x7fdfd0704ac0>, <keras.layers.regularization.dropout.Dropout object at 0x7fdfd0706140>, <keras.layers.core.dense.Dense object at 0x7fdfd0706b00>, <keras.layers.regularization.dropout.Dropout object at 0x7fdfd0707430>, <keras.layers.core.dense.Dense object at 0x7fdfd0704d30>]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 376, 30)           3030      \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 188, 30)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 188, 30)           0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 164, 30)           22530     \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 82, 30)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 82, 30)            0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2460)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              2520064   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,676,953\n",
      "Trainable params: 2,676,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_baseline()\n",
    "\n",
    "print(model.layers)\n",
    "\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20818404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#showing the mean and standard deviation of the estimated accuracy of the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "598f4eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 76.35% (1.57%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(model=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv=kfold) #change to x_val and y_val\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d43ea",
   "metadata": {},
   "source": [
    "# 2.2 .fit() \n",
    "- Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "454b591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a09bf344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 118890), started 0:52:08 ago. (Use '!kill 118890' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e4ec664981489543\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e4ec664981489543\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65d21c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/40\n",
      "134/134 [==============================] - 4s 21ms/step - loss: 0.6305 - accuracy: 0.6435 - val_loss: 0.5477 - val_accuracy: 0.7291\n",
      "Epoch 2/40\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.5477 - accuracy: 0.7338 - val_loss: 0.5565 - val_accuracy: 0.7245\n",
      "Epoch 3/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.5252 - accuracy: 0.7483 - val_loss: 0.5346 - val_accuracy: 0.7545\n",
      "Epoch 4/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.5031 - accuracy: 0.7607 - val_loss: 0.4870 - val_accuracy: 0.7835\n",
      "Epoch 5/40\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.4877 - accuracy: 0.7785 - val_loss: 0.4730 - val_accuracy: 0.8004\n",
      "Epoch 6/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.4628 - accuracy: 0.7898 - val_loss: 0.4836 - val_accuracy: 0.7882\n",
      "Epoch 7/40\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.4403 - accuracy: 0.7966 - val_loss: 0.4681 - val_accuracy: 0.7891\n",
      "Epoch 8/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.4072 - accuracy: 0.8184 - val_loss: 0.4590 - val_accuracy: 0.8013\n",
      "Epoch 9/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.3807 - accuracy: 0.8306 - val_loss: 0.4428 - val_accuracy: 0.8144\n",
      "Epoch 10/40\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.3614 - accuracy: 0.8488 - val_loss: 0.4780 - val_accuracy: 0.7779\n",
      "Epoch 11/40\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.3370 - accuracy: 0.8584 - val_loss: 0.4499 - val_accuracy: 0.7985\n",
      "Epoch 12/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.3060 - accuracy: 0.8711 - val_loss: 0.4356 - val_accuracy: 0.8032\n",
      "Epoch 13/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.2888 - accuracy: 0.8734 - val_loss: 0.4755 - val_accuracy: 0.7957\n",
      "Epoch 14/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.2698 - accuracy: 0.8828 - val_loss: 0.4524 - val_accuracy: 0.7901\n",
      "Epoch 15/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.2458 - accuracy: 0.8952 - val_loss: 0.4807 - val_accuracy: 0.8032\n",
      "Epoch 16/40\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 0.2329 - accuracy: 0.9025 - val_loss: 0.4984 - val_accuracy: 0.7854\n",
      "Epoch 17/40\n",
      "134/134 [==============================] - 2s 16ms/step - loss: 0.2366 - accuracy: 0.9046 - val_loss: 0.4742 - val_accuracy: 0.8013\n"
     ]
    }
   ],
   "source": [
    "#second is to use .fit() --> to train the model : use x_train, y_train --> either .fit() or training loop from scratch (see below)\n",
    "print(\"Fit model on training data\")\n",
    "\n",
    "model = create_baseline()\n",
    "\n",
    "import datetime\n",
    "#%tensorboard --logdir logs/fit\n",
    "#parameters \n",
    "#batch_size=32\n",
    "epochs= 40\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    #batch_size=batch_size, # --> the tf.dataset already batched the dataset \n",
    "    epochs=epochs,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val,y_val),\n",
    "    callbacks=my_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d76c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/20\n",
      "134/134 [==============================] - 3s 14ms/step - loss: 0.6202 - accuracy: 0.6508\n",
      "Epoch 2/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.5504 - accuracy: 0.7324\n",
      "Epoch 3/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.5203 - accuracy: 0.7528\n",
      "Epoch 4/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.5061 - accuracy: 0.7663\n",
      "Epoch 5/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.4772 - accuracy: 0.7813\n",
      "Epoch 6/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.4515 - accuracy: 0.7954\n",
      "Epoch 7/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.4237 - accuracy: 0.8092\n",
      "Epoch 8/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.4064 - accuracy: 0.8163\n",
      "Epoch 9/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.3805 - accuracy: 0.8399\n",
      "Epoch 10/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.3749 - accuracy: 0.8355\n",
      "Epoch 11/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.3396 - accuracy: 0.8577\n",
      "Epoch 12/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.3168 - accuracy: 0.8659\n",
      "Epoch 13/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2970 - accuracy: 0.8760\n",
      "Epoch 14/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2810 - accuracy: 0.8816\n",
      "Epoch 15/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2509 - accuracy: 0.9018\n",
      "Epoch 16/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2422 - accuracy: 0.9002\n",
      "Epoch 17/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2249 - accuracy: 0.9074\n",
      "Epoch 18/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.2163 - accuracy: 0.9126\n",
      "Epoch 19/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1999 - accuracy: 0.9213\n",
      "Epoch 20/20\n",
      "134/134 [==============================] - 2s 14ms/step - loss: 0.1961 - accuracy: 0.9217\n"
     ]
    }
   ],
   "source": [
    "#second is to use .fit() --> to train the model : use x_train, y_train --> either .fit() or training loop from scratch (see below)\n",
    "print(\"Fit model on training data\")\n",
    "#%tensorboard --logdir logs/fit\n",
    "\n",
    "model = create_baseline()\n",
    "\n",
    "#parameters \n",
    "#batch_size=32\n",
    "epochs= 20\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    #batch_size=batch_size, --> the tf.dataset already batched the dataset \n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef6898a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 118890), started 0:53:20 ago. (Use '!kill 118890' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c5673c9be2f3fa62\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c5673c9be2f3fa62\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c77bdd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/sofia.martello/miniconda3/envs/my-thesis-env/lib/python3.10/site-packages/keras/backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.5061\n",
      "Time taken: 0.89s\n",
      "\n",
      "Start of epoch 1\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.5061\n",
      "Time taken: 0.83s\n",
      "\n",
      "Start of epoch 2\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.5342\n",
      "Time taken: 0.82s\n",
      "\n",
      "Start of epoch 3\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.80s\n",
      "\n",
      "Start of epoch 4\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.82s\n",
      "\n",
      "Start of epoch 5\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.81s\n",
      "\n",
      "Start of epoch 6\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.81s\n",
      "\n",
      "Start of epoch 7\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.79s\n",
      "\n",
      "Start of epoch 8\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.80s\n",
      "\n",
      "Start of epoch 9\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.79s\n",
      "\n",
      "Start of epoch 10\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.81s\n",
      "\n",
      "Start of epoch 11\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.80s\n",
      "\n",
      "Start of epoch 12\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.80s\n",
      "\n",
      "Start of epoch 13\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.81s\n",
      "\n",
      "Start of epoch 14\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.84s\n",
      "\n",
      "Start of epoch 15\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.79s\n",
      "\n",
      "Start of epoch 16\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.79s\n",
      "\n",
      "Start of epoch 17\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.4939\n",
      "Time taken: 0.80s\n",
      "\n",
      "Start of epoch 18\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.5661\n",
      "Time taken: 0.80s\n",
      "\n",
      "Start of epoch 19\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Training acc over epoch: 0.0000\n",
      "Validation acc: 0.6129\n",
      "Time taken: 0.80s\n"
     ]
    }
   ],
   "source": [
    "#first attempt of a training loop from scratch --> added the evaluation loop here --> WORKS WITH TF.DATASETS\n",
    "\n",
    "model = create_baseline()\n",
    "\n",
    "\n",
    "#parameters\n",
    "#input_shape = (3388, 401, 4)\n",
    "input_shape = (400, 4)\n",
    "epochs = 20 #for the test \n",
    "#optimizer = keras.optimizers.SGD(learning_rate=1e-3)#or adam ? --> check  \n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)#parameter is recommended as true but creates an error\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = keras.metrics.BinaryAccuracy()\n",
    "val_acc_metric = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "\n",
    "model = create_baseline()\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate over the batches of the dataset.\n",
    "    #for step, (x_batch_train, y_batch_train) in enumerate(train_dataset): #55 steps\n",
    "        #print(step)\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "        logits = model(x_train, training=True)  \n",
    "            #print(\"Number of weights after calling the model:\", len(model.weights))\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "        loss_value = loss_fn(y_train, logits)\n",
    "    \n",
    "            \n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    \n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights)) #I think it doesn't work because there's just one class now . \n",
    "\n",
    "        # Log every 200 batches.\n",
    "        #if (step % 50) == 0:\n",
    "         #   print(\n",
    "          #      \"Training loss (for one batch) at step %d: %.4f\"\n",
    "            #    % (step, float(loss_value))\n",
    "            #)\n",
    "            #print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(train_acc)\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "   # for x_batch_val, y_batch_val in val_dataset:\n",
    "    val_logits = model(x_val, training=False)\n",
    "\n",
    "        # Update val metrics\n",
    "    val_acc_metric.update_state(y_val, val_logits)\n",
    "    \n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d02d78aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Iterate over the batches of the dataset.\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (x_batch_train, y_batch_train) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_dataset\u001b[49m): \u001b[38;5;66;03m#55 steps\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#print(step)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Open a GradientTape to record the operations run\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# during the forward pass, which enables auto-differentiation.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# Run the forward pass of the layer.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;66;03m# The operations that the layer applies\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# to its inputs are going to be recorded\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;66;03m# on the GradientTape.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         logits \u001b[38;5;241m=\u001b[39m model(x_batch_train, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#first attempt of a training loop from scratch --> added the evaluation loop here --> WORKS WITH TF.DATASETS\n",
    "\n",
    "#parameters\n",
    "#input_shape = (3388, 401, 4)\n",
    "input_shape = (400, 4)\n",
    "epochs = 5 #for the test \n",
    "#optimizer = keras.optimizers.SGD(learning_rate=1e-3)#or adam ? --> check  \n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=False)#parameter is recommended as true \n",
    "# Prepare the metrics.\n",
    "train_acc_metric = keras.metrics.BinaryAccuracy()\n",
    "val_acc_metric = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "\n",
    "model = create_baseline()\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset): #55 steps\n",
    "        #print(step)\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = model(x_batch_train, training=True)  \n",
    "            #print(\"Number of weights after calling the model:\", len(model.weights))\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "    \n",
    "            \n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    \n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights)) #I think it doesn't work because there's just one class now . \n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if (step % 50) == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9231490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_class = y_pred_pos > threshold\n",
    "cm = confusion_matrix(y_true, y_pred_class)\n",
    "tn, fp, fn, tp = cm.ravel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-thesis-env)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
