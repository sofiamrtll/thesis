{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637bc311",
   "metadata": {},
   "source": [
    "# THESIS - Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a92bfc",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05792d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shlex, subprocess\n",
    "import os , sys\n",
    "sys.path.append('/home/ubuntu/')\n",
    "os.chdir('/home/ubuntu/')\n",
    "\n",
    "import importlib\n",
    "import src\n",
    "importlib.reload(src.model)\n",
    "import src.model as mdl\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import keras_tuner\n",
    "\n",
    "from Bio import SeqIO\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953462e2-f55a-48dd-8307-ad4d20ad35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all paths\n",
    "datapath = '/mnt/data/'\n",
    "resultspath = '/home/ubuntu/results/'\n",
    "predictionspath = '/home/ubuntu/results/all_predictions/'\n",
    "plotspath = '/home/ubuntu/results/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006f771",
   "metadata": {},
   "source": [
    "# 1. Preparation of the dataset \n",
    "- One hot encoding the sequences \n",
    "- Dataset Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a078fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "def fasta_to_onehotencode(seq) : \n",
    "    #values = list(seq)\n",
    "    #values = np.array(values)\n",
    "    base2int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    # label = int(line.strip()[1])\n",
    "    \n",
    "    \n",
    "    sequence = seq \n",
    "    # Encode sequence bases as integers, i.e. A as 0, C as 1, etc.\n",
    "    sequence_int = [base2int.get(base, 9999) for base in sequence]\n",
    "    \n",
    "    sequence_onehot = tf.one_hot(sequence_int, depth=4)\n",
    "    \n",
    "        \n",
    "    return sequence_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1f4360b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastatoarray(fasta_sequences) :\n",
    "    seq_array = np.zeros((1,400,4)) \n",
    "    for fasta in fasta_sequences:\n",
    "        name, sequence = fasta.id, str(fasta.seq)\n",
    "        new_sequence = fasta_to_onehotencode(sequence) #onehotencode(sequence)\n",
    "        new_sequence = np.expand_dims(new_sequence, axis =0)\n",
    "        seq_array = np.vstack((seq_array,new_sequence))\n",
    "    seq_array = np.delete(seq_array, 0, 0) #to remove the first array of zeros \n",
    "    return seq_array                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f658b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_start_time = time.time()\n",
    "#change a bit this function or cite \n",
    "def tic():\n",
    "    global _start_time \n",
    "    _start_time = time.time()\n",
    "\n",
    "def tac():\n",
    "    t_sec = round(time.time() - _start_time)\n",
    "    (t_min, t_sec) = divmod(t_sec,60)\n",
    "    (t_hour,t_min) = divmod(t_min,60) \n",
    "    print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path) : \n",
    "    current_folder = folder\n",
    "    directory2 = os.listdir(path + '/' + folder)\n",
    "    seq_list_positive = np.zeros((1,400,4)) \n",
    "    seq_list_negative = np.zeros((1,400,4)) \n",
    "    seq_list_positive_test = np.zeros((1,400,4)) \n",
    "    seq_list_negative_test = np.zeros((1,400,4)) \n",
    "\n",
    "    for folder2 in directory2 :\n",
    "        directory3 = os.listdir(path+ '/' + folder + '/' + folder2)\n",
    "\n",
    "        if folder2 != \"fold-4\": #to be split into training and validation\n",
    "            seq_list_positive_file = np.zeros((1,400,4)) \n",
    "            seq_list_negative_file = np.zeros((1,400,4)) \n",
    "\n",
    "            for file in directory3 :\n",
    "\n",
    "                if \"fasta\" in file :\n",
    "                    fasta_sequences = SeqIO.parse(open(path+ '/' + folder + '/' + folder2+ '/' + file),'fasta')\n",
    "                    seq_array = fastatoarray(fasta_sequences)\n",
    "\n",
    "                    if \"positive\" in file : \n",
    "                        seq_list_positive_file = np.vstack((seq_list_positive_file, seq_array))\n",
    "\n",
    "                    if \"negative-1\" in file: # 2 neg: 1 pos with 'negative' --> 1 neg : 1 pos 'negative-1'\n",
    "                        seq_list_negative_file = np.vstack((seq_list_negative_file, seq_array))\n",
    "\n",
    "            seq_list_negative_file = np.delete(seq_list_negative_file, 0, 0)\n",
    "            seq_list_positive_file = np.delete(seq_list_positive_file, 0, 0)\n",
    "\n",
    "            seq_list_positive = np.vstack((seq_list_positive, seq_list_positive_file))\n",
    "            seq_list_negative = np.vstack((seq_list_negative, seq_list_negative_file))\n",
    "\n",
    "        if folder2 == \"fold-4\": #this folder will be used for testing\n",
    "\n",
    "                seq_list_positive_test_file = np.zeros((1,400,4)) \n",
    "                seq_list_negative_test_file = np.zeros((1,400,4)) \n",
    "\n",
    "                for file in directory3 :\n",
    "\n",
    "                    if \"fasta\" in file :\n",
    "                        fasta_sequences = SeqIO.parse(open(path+ '/' + folder + '/' + folder2+ '/' + file),'fasta')\n",
    "                        seq_array = fastatoarray(fasta_sequences)\n",
    "\n",
    "                        if \"positive\" in file : \n",
    "                            seq_list_positive_test_file = np.vstack((seq_list_positive_test_file, seq_array))\n",
    "\n",
    "                        if \"negative-1\" in file: \n",
    "                            seq_list_negative_test_file = np.vstack((seq_list_negative_test_file, seq_array))\n",
    "\n",
    "                seq_list_negative_test_file = np.delete(seq_list_negative_test_file, 0, 0)\n",
    "                seq_list_positive_test_file = np.delete(seq_list_positive_test_file, 0, 0)\n",
    "\n",
    "                seq_list_positive_test = np.vstack((seq_list_positive_test, seq_list_positive_test_file))\n",
    "                seq_list_negative_test = np.vstack((seq_list_negative_test, seq_list_negative_test_file))\n",
    "\n",
    "                seq_list_negative_test = np.delete(seq_list_negative_test, 0, 0)\n",
    "                seq_list_positive_test = np.delete(seq_list_positive_test, 0, 0)  \n",
    "\n",
    "    seq_list_negative = np.delete(seq_list_negative, 0, 0)\n",
    "    seq_list_positive = np.delete(seq_list_positive, 0, 0)\n",
    "    \n",
    "    \n",
    "    #Preparation of the labels\n",
    "    labels_positive = np.ones((np.shape(seq_list_positive)[0], 1))\n",
    "    labels_negative = np.zeros((np.shape(seq_list_negative)[0], 1))\n",
    "    labels_positive_test = np.ones((np.shape(seq_list_positive_test)[0], 1))\n",
    "    labels_negative_test = np.zeros((np.shape(seq_list_negative_test)[0], 1))\n",
    "    print('Shape of labels: \\n-positive : ',np.shape(labels_negative),'\\n-negative : ', np.shape(labels_negative),'\\n-positive validation : ',np.shape(labels_positive_test),'\\n-negative validation : ',np.shape(labels_negative_test))\n",
    "    \n",
    "    \n",
    "    #Merging datasets\n",
    "    x = np.vstack((seq_list_positive, seq_list_negative))\n",
    "    x_test = np.vstack((seq_list_positive_test, seq_list_negative_test))\n",
    "    y = np.vstack((labels_positive, labels_negative))\n",
    "    y_test = np.vstack((labels_positive_test, labels_negative_test))\n",
    "\n",
    "    \n",
    "    #Splitting dataset  : test, train and validation sets\n",
    "    test_size = 0.2\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=test_size, shuffle= True)\n",
    "    x_test, y_test = shuffle(x_test, y_test, random_state=0)\n",
    "\n",
    "    y_train = y_train.astype(\"float32\")#actually useful?\n",
    "    y_val =y_val.astype(\"float32\")\n",
    "    y_test = y_test.astype(\"float32\")\n",
    "\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_val = x_val.astype(\"float32\")\n",
    "    x_test =x_test.astype(\"float32\")\n",
    "    \n",
    "    print('Shape of datasets: \\n-training set : ',np.shape(x_train),'\\n-validation set : ',np.shape(x_val),'\\n-testing set : ', np.shape(x_test))\n",
    "    \n",
    "    #Checking class ditribution in the whole dataset and training set\n",
    "\n",
    "    print('Label frequencies among the dataset')\n",
    "    plt.hist(y)\n",
    "    plt.xticks(range(2))\n",
    "    plt.title('Label Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(y_train)\n",
    "    plt.xticks(range(2))\n",
    "    plt.title('Label Frequency training set')\n",
    "    plt.show()\n",
    "\n",
    "    plt.hist(y_val)\n",
    "    plt.xticks(range(2))\n",
    "    plt.title('Label Frequency validation set')\n",
    "    plt.show()\n",
    "    return x_train ,y_train ,x_val ,y_val ,x_test ,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e28b8-d592-4091-af2f-dd7baf3f2bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89762bc1",
   "metadata": {},
   "source": [
    "# 2. Standard Model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc4e6e",
   "metadata": {},
   "source": [
    "# 2.1 Create the baseline model \n",
    "- Initial model architecture inspired by pysster (citation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a92b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_baseline():\n",
    "    \n",
    "    METRICS = [\n",
    "        keras.metrics.TruePositives(name='tp'),\n",
    "        keras.metrics.FalsePositives(name='fp'),\n",
    "        keras.metrics.TrueNegatives(name='tn'),\n",
    "        keras.metrics.FalseNegatives(name='fn'), \n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(curve= 'ROC',name='auroc'),\n",
    "        keras.metrics.AUC(curve = 'PR', name='auprc') \n",
    "    ]\n",
    "\n",
    "    #Parameters \n",
    "    input_shape = (400, 4)\n",
    "    filters = 30\n",
    "    kernel_size = 25\n",
    "    pool_size = 2\n",
    "    strides = 2\n",
    "    loss='binary_crossentropy'\n",
    "    optimizer='adam' \n",
    "    metrics=['accuracy']\n",
    "    \n",
    "    #Create model    \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape= input_shape))\n",
    "    model.add(keras.layers.Conv1D(filters=filters,kernel_size=kernel_size,\n",
    "              kernel_initializer='random_normal',\n",
    "              activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=pool_size, strides=strides, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Conv1D(filters=filters,kernel_size=kernel_size,\n",
    "              kernel_initializer= 'random_normal', \n",
    "              activation='relu',input_shape=input_shape ))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=pool_size, strides=strides, padding='valid'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics= METRICS)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cddd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.layers.convolutional.conv1d.Conv1D object at 0x7f74bc36faf0>, <keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7f74bc36d660>, <keras.layers.regularization.dropout.Dropout object at 0x7f74bc36f340>, <keras.layers.convolutional.conv1d.Conv1D object at 0x7f74bc4e9ff0>, <keras.layers.pooling.max_pooling1d.MaxPooling1D object at 0x7f74bc36e320>, <keras.layers.regularization.dropout.Dropout object at 0x7f74caee6fe0>, <keras.layers.reshaping.flatten.Flatten object at 0x7f74bc3bdd20>, <keras.layers.core.dense.Dense object at 0x7f74bc3bdf30>, <keras.layers.regularization.dropout.Dropout object at 0x7f74bc3be140>, <keras.layers.core.dense.Dense object at 0x7f74bc3bcc10>, <keras.layers.regularization.dropout.Dropout object at 0x7f74bc3bf220>, <keras.layers.core.dense.Dense object at 0x7f74bc3bf7f0>]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 376, 30)           3030      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 188, 30)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 188, 30)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 164, 30)           22530     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 82, 30)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 82, 30)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2460)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2520064   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,676,953\n",
      "Trainable params: 2,676,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Summary of the model\n",
    "model = create_baseline()\n",
    "\n",
    "print(model.layers)\n",
    "\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2514d86",
   "metadata": {},
   "source": [
    "# 2.2 Fitting and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f3d6724-060d-4a23-9848-c690ca0c1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fit model on training data\")\n",
    "def fit_standard(x_train,y_train,x_val,y_val, folder):\n",
    "    \n",
    "    model = create_baseline()\n",
    "\n",
    "    #Parameters \n",
    "    epochs= 50 \n",
    "    my_callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5),#introducing EarlyStopping to avoid overfitting\n",
    "        #tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    ]\n",
    "\n",
    "    history = model.fit(x_train,y_train,epochs=epochs,validation_data=(x_val,y_val),callbacks=my_callbacks)\n",
    "\n",
    "    # list all data in history\n",
    "\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for auroc \n",
    "    plt.plot(history.history['auroc'])\n",
    "    plt.plot(history.history['val_auroc'])\n",
    "    plt.plot(history.history['auprc'])\n",
    "    plt.plot(history.history['val_auprc'])\n",
    "    plt.title('model auroc and auprc')\n",
    "    plt.ylabel('auroc and auprc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['auroc_train', 'auroc_test','auprc_train', 'auprc_test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    model.save(f'{resultspath}best_models/standard_model_%s' % current_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36651927",
   "metadata": {},
   "source": [
    "# 2.3 Testing and saving the Standard model\n",
    "- Testing on the same folder on which later the architecture is going to be tuned, for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d04dde-c11c-400a-b039-20b4aef5c652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_standard(model_path,x_test,y_test,folder):\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "\n",
    "    #testing and saving the predictions \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    '''def plot_PRC(y_test, y_pred): \n",
    "        plot = PrecisionRecallDisplay.from_predictions(y_test, y_pred)\n",
    "        pl= plot.ax_.set_title(\"Precision-Recall curve\")\n",
    "        return pl'''\n",
    "    #Precision Recall Curve\n",
    "    plt = mdl.plot_PRC(y_test, y_pred)\n",
    "    plt.savefig(f'{plotspath}PRC{current_folder}_standard.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    '''def plot_ROC(y_test, y_pred):\n",
    "\n",
    "        false_pr, true_pr, thresholds = metrics.roc_curve(y_test, y_pred, drop_intermediate=False)\n",
    "\n",
    "        # Generate figure\n",
    "\n",
    "        fig = pl.figure(figsize=(14,7))\n",
    "        ax = fig.add_subplot(121)\n",
    "\n",
    "        pl.plot(false_pr, true_pr, label=\" (AUC=%.2f)\" % metrics.roc_auc_score(y_test, y_pred))\n",
    "        ax.plot([0,1], [0,1], color=\"grey\",label=\"Random Classifier\",linestyle=\"--\")\n",
    "        ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.set_ylabel(\"True Positive Rate\")\n",
    "        ax.set_ylim(0,1)\n",
    "        ax.set_xlim(0,1)\n",
    "        ax.grid(color=\"#CCCCCC\")\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        pl.legend()\n",
    "        pl.tight_layout()\n",
    "        return pl\n",
    "    '''\n",
    "    #Receiver Operating Characteristics \n",
    "    plt = mdl.plot_ROC(y_test, y_pred)\n",
    "    plt.savefig(f'{plotspath}ROC{current_folder}_standard.png', bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de944fe",
   "metadata": {},
   "source": [
    "# 3. Finding the best model via Random Search\n",
    "- Identification of the optimal parameters\n",
    "- Saving of the model after its evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d0239-39e5-427e-acc3-3d0cccf7af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    \n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(curve= 'ROC',name='auroc'),\n",
    "      keras.metrics.AUC(curve = 'PR', name='auprc')  \n",
    "    ]\n",
    "    \n",
    "    input_shape = (400, 4)\n",
    "    \n",
    "    #Hyperparameter search \n",
    "    \n",
    "    hp_filters = hp.Int('filters', min_value = 10, max_value = 60, step = 10)\n",
    "    hp_kernel_size = hp.Int('kernel_size', min_value = 10, max_value = 60, step = 5)\n",
    "    hp_pool_size = hp.Int('pool_size', min_value = 1, max_value = 10, step = 1)\n",
    "    hp_strides = hp.Int('strides', min_value = 1, max_value = 10, step = 1)\n",
    "    hp_learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    #hp_padding = hp.Choice('padding', ['valid','same'])\n",
    "    hp_padding = 'same' \n",
    "    hp_kernel_initializer = hp.Choice('initiaizer', ['random_normal','random_uniform'])\n",
    "    hp_activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    \n",
    "    \n",
    "    #Create model\n",
    "      \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape= input_shape))\n",
    "    model.add(keras.layers.Conv1D(filters=hp_filters,kernel_size=hp_kernel_size,\n",
    "              kernel_initializer=hp_kernel_initializer, \n",
    "              activation=hp_activation,input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=hp_pool_size, strides=hp_strides, padding=hp_padding))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Conv1D(filters=hp_filters,kernel_size=hp_kernel_size,\n",
    "              kernel_initializer= hp_kernel_initializer, \n",
    "              activation=hp_activation ,input_shape=input_shape ))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=hp_pool_size, strides=hp_strides, padding=hp_padding))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Flatten())#without parameters\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "        layers.Dense(\n",
    "            # Tune number of units separately.\n",
    "            units=hp.Int(f\"units_{i}\", min_value=32, max_value=1024, step=32),\n",
    "            activation = hp_activation\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=hp_activation))\n",
    "    model.add(keras.layers.Dropout(0.6))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))#what should be the output shape? 1? \n",
    "\n",
    "    \n",
    "    #many models train better when reducing the learning rate gradually -- not in this case\n",
    "    #lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "                                                                 # 0.001,\n",
    "                                                                 # decay_steps=50*1000,\n",
    "                                                                 # decay_rate=1,\n",
    "                                                                  #staircase=False)\n",
    "    \n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(hp_learning_rate), metrics=METRICS)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_best_model(x_train ,y_train ,x_val ,y_val ,x_test ,y_test) : \n",
    "        METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(curve= 'ROC',name='auroc'),\n",
    "      keras.metrics.AUC(curve = 'PR', name='auprc')  \n",
    "    ]\n",
    "    \n",
    "    my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2,restore_best_weights=True), #restore best weights added later), #better to reduce to 2 for the search \n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    #tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    ]\n",
    "\n",
    "    \n",
    "    model = build_model(keras_tuner.HyperParameters())\n",
    "    print(model.summary())\n",
    "\n",
    "    tuner = keras_tuner.RandomSearch(\n",
    "        hypermodel=build_model,\n",
    "        #objective=keras_tuner.Objective(\"val_auroc\", direction=\"max\"), #val_loss , val_accuracy .... 77\n",
    "        #objective = keras_tuner.Objective(\"val_loss\", direction=\"min\"),\n",
    "        objective=\"val_accuracy\",\n",
    "        max_trials=200,\n",
    "        executions_per_trial=1, #probably better to change to 1 and increase the max_trials\n",
    "        overwrite=False, #I found the best combination\n",
    "        directory=\"my_dir\",\n",
    "        project_name=\"models\",\n",
    "        max_consecutive_failed_trials=10,\n",
    "    )\n",
    "\n",
    "    print(tuner.search_space_summary())\n",
    "    tuner.search(x_train, y_train, epochs=5, validation_data=(x_val, y_val))\n",
    "    \n",
    "   ''' # Get the top 2 models.\n",
    "    models = tuner.get_best_models(num_models=4)\n",
    "    best_model = models[0]\n",
    "    # Build the model.\n",
    "    best_model.build(input_shape=(None, 400, 4))\n",
    "    best_model.summary() #is this block relevant? '''\n",
    "    \n",
    "\n",
    "    best_hps = tuner.get_best_hyperparameters(5)\n",
    "    #SAVE THESE HYPERPARAMETERS AND USE THEM FOR create_baseline_model()\n",
    "    #at this point the optimal parameters have been identified, the next part of training and prediction is the same for all models \n",
    "    \n",
    "    # Build the model with the best hp.\n",
    "    model = build_model(best_hps[0])\n",
    "    \n",
    "    #saving the best model for testing and aggregated evaluation later\n",
    "    model.save(f'{resultspath}best_models/best_hps_model') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c5a10ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir/helloworld\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fdfadf977f0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 896\n",
      "dropout: True\n",
      "lr: 0.0004893954054196937\n",
      "units_1: 32\n",
      "units_2: 32\n",
      "Score: 0.7426763574282328\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 192\n",
      "dropout: True\n",
      "lr: 0.0016380235981496075\n",
      "units_1: 800\n",
      "units_2: 192\n",
      "Score: 0.7310366233189901\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 960\n",
      "dropout: False\n",
      "lr: 0.00035910093218825\n",
      "units_1: 32\n",
      "units_2: 64\n",
      "Score: 0.6654948790868124\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 384\n",
      "dropout: False\n",
      "lr: 0.00024335509762462415\n",
      "units_1: 224\n",
      "units_2: 160\n",
      "Score: 0.6505741675694784\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 448\n",
      "dropout: False\n",
      "lr: 0.000501777635589437\n",
      "units_1: 96\n",
      "units_2: 928\n",
      "Score: 0.6414342522621155\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047511fd-4f45-4b81-bd63-0fd40a499567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(x_train ,y_train ,x_val ,y_val ,x_test ,y_test, folder) : \n",
    "    \n",
    "    \n",
    "    \n",
    "    METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(curve= 'ROC',name='auroc'),\n",
    "      keras.metrics.AUC(curve = 'PR', name='auprc')  \n",
    "    ]\n",
    "    \n",
    "    \n",
    "    my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5), #better to reduce to 2 for the search \n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    ]\n",
    "    \n",
    "    #fitting the model\n",
    "\n",
    "    model = keras.models.load_model('best_models/best_hps_model')\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=200, validation_data= (x_val,y_val), callbacks = my_callbacks)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # list all data in history --> add name of the rbp!!!!\n",
    "\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    plt.title('Best model evaluation for %s' %folder)\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy %s'  %folder)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss %s'  %folder)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for auroc \n",
    "    plt.plot(history.history['auroc'])\n",
    "    plt.plot(history.history['val_auroc'])\n",
    "    plt.plot(history.history['auprc'])\n",
    "    plt.plot(history.history['val_auprc'])\n",
    "    plt.title('model auroc and auprc %s'  %folder)\n",
    "    plt.ylabel('auroc and auprc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['auroc_train', 'auroc_test','auprc_train', 'auprc_test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    model.save('best_models/best_model_base%s' %folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89248c",
   "metadata": {},
   "source": [
    "# 3.2 Testing the model \n",
    "- Testing using different methods (Precision Recall Curve, ROC Curve, Confusion Matrix)\n",
    "- Saving the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319565a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(path , current_folder, x_test, y_test) : \n",
    "    #reloading the model to compute the predictions\n",
    "    reconstructed_model = keras.models.load_model(path)\n",
    "    y_pred = reconstructed_model.predict(x_test)\n",
    "    threshold = 0.5\n",
    "    y_pred_thresh = np.where(y_pred > threshold, 1,0)\n",
    "    \n",
    "    #Precision Recall Curve \n",
    "    plt = mdl.plot_PRC(y_test, y_pred)\n",
    "    plt.savefig(f'{plotspath}PRC{current_folder}_opt.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    #Receiver Operating Characteristics\n",
    "    plt = mdl.plot_ROC(y_test, y_pred)\n",
    "    plt.savefig(f'{plotspath}ROC{current_folder}_opt.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    #Confusion Matrix\n",
    "    plt= mdl.plot_CM(y_test, y_pred_thresh)\n",
    "    plt.savefig(f'{plotspath}MC{current_folder}_opt.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    '''\n",
    "    def plot_CM(y_test, y_pred):\n",
    "        matrix = confusion_matrix(y_test, y_pred)\n",
    "        names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "        counts = ['{0:0.0f}'.format(value) for value in\n",
    "                        matrix.flatten()]\n",
    "        percentages = ['{0:.2%}'.format(value) for value in\n",
    "                             matrix.flatten()/np.sum(matrix)]\n",
    "        labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "                  zip(names,counts,percentages)]\n",
    "        labels = np.asarray(labels).reshape(2,2)\n",
    "        plot = sns.heatmap(matrix, annot=labels, fmt='', cmap='Blues')\n",
    "        return plot'''\n",
    "    #saving the predictions (0,1) in a csv file -- in probabilities \n",
    "    df= pd.DataFrame(y_pred, columns = ['Predictions'])\n",
    "    df['True'] = y_test\n",
    "    df.to_csv(f\"{predictionspath}predictions/%s.csv\" % current_folder)\n",
    "    print(\"Prediction saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e75e73-b1ec-4cb4-933d-9b7cb2515082",
   "metadata": {},
   "source": [
    "# Processing one RBP\n",
    "- The chosen protein is '', which has high methylation rate and this could improve the ability of the model to discern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae197e63-68f4-4814-bda6-992332ac9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{datapath}processed/ENCODE-Sofia/'\n",
    "folder = ''\n",
    "tic()\n",
    "\n",
    "#Standard model\n",
    "#preparation of the dataset \n",
    "x_train ,y_train ,x_val ,y_val ,x_test ,y_test = prepare_dataset(path, folder) #prepares the dataset in one CV configuration\n",
    "\n",
    "fit_standard(x_train,y_train,x_val,y_val, folder)\n",
    "\n",
    "model_path = f'{resultspath}best_models/standard_model_%s' % current_folder)\n",
    "test_standard(model_path,x_test,y_test,folder)\n",
    "\n",
    "\n",
    "#Tuned model\n",
    "#preparation of the dataset \n",
    "x_train ,y_train ,x_val ,y_val ,x_test ,y_test = prepare_dataset(path, folder) #prepares the dataset in one CV configuration\n",
    "\n",
    "#prepare and save the best model  \n",
    "prepare_best_model(x_train ,y_train ,x_val ,y_val ,x_test ,y_test, folder) #saves the best configuration of hyperparameters \n",
    "\n",
    "#training the model on the new datasets\n",
    "training_model(x_train ,y_train ,x_val ,y_val ,x_test ,y_test, folder) #best model is not trained on any data\n",
    "\n",
    "#evaluation and storage of the predicted labels\n",
    "model_path = (f'{resultspath}best_models/best_model_%s' % folder)\n",
    "testing_model(model_path , folder, x_test, y_test)\n",
    "\n",
    "tac()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cfb2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637247ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
